{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Хакатон по распознаванию хот-догов. \nПо мотивам крутейшего стартапа из сериала \"кремниевая долина\"!\n\nhttps://www.youtube.com/watch?v=pqTntG1RXSY\n\n\nВаша задача: сделать революционный классификатор, который сразил большинство инвесторов и гиков из кремниевой долины не один раз!\n\nТочнее, вам необходимо предсказать, есть на изображении хот-дог или нет. В файл с решением необходимо записать вероятность того, что на изображении **есть хот-дог**.\n\nКачество модели будет измеряться с помощью метрики AUC-ROC, публичный лидерборд (рейтинговая таблица соревнования на платформе kaggle) будет строиться по 50% наблюдений. \n\nЧуть подробнее про публичный и приватный лидерборд: вам дана тестовая выборка, для которой неизвестна целевая переменная. Вы обучаете модель, предсказываете для тестовой выборки, формируете из предсказаний csv-файл, и загружаете его на платформу kaggle. Видите значение метрики AUC-ROC. Это значение называется метрикой на публичном лидерборде, и считается оно не по всем данным, а лишь по 50% от тестовой выборки. Когда соревнование заканчивается, AUC-ROC пересчитывается уже для 100% тестовой выборки, и это уже называется приватный лидерборд, он же - финальный.\n\nТакой подход является классическим для большей части соревнований по анализу данных, и основан он на том, что если не делать такого разделения, то будет происходить неявное переобучение модели под тестовую выборку. \n\nНа этом вводная часть заканчивается, и мы искренне желаем вам удачи :) <br>\nСможете ли вы повторить успех Jian Yuang'a? Мы в вас верим!\n\n<hr>"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\n\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom matplotlib.image import imread\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport PIL","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\n#print(os.listdir(\"../input/train/train/\"))\nprint(os.listdir(\"../input/train2/train2/train2/\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Разархивируем файлы с данными и импортируем необходимые библиотеки"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#!unzip -q -o test.zip\n#!unzip -q -o train.zip","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"font = {\n    'family': 'serif',\n    'color':  'darkred',\n    'weight': 'bold',\n    'size': 22,\n}\nSEED = 257\n#TRAIN_DIR = '../input/train/train/'\nTRAIN_DIR = '../input/train2/train2/train2/'\nTEST_DIR = '../input/test/test/'\ncategories = ['hot dog', 'not hot dog']\n\nimage_width = 100\nimage_height = 100\nX, y = [], []\nfor category in categories:\n    category_dir = os.path.join(TRAIN_DIR, category)\n    for image_path in os.listdir(category_dir):\n        if not (image_path.endswith('.png')):\n            continue \n        image = PIL.Image.open(os.path.join(category_dir, image_path))#.convert(\"L\")\n        if (image.width == image_width) and (image.height == image_height):\n            X.append(np.array(image))\n        if category=='hot dog': \n            y.append(1) \n        else: \n            y.append(0)\n        #y.append(category)\n        \nX_array = np.array(X)#.reshape(len(X), image_width, image_height, 1)\nY_array = np.array(y) \n#Y_array_encoded = [1 if x == 'hot dog' else 0 for x in Y_array]\nfrom tensorflow.keras.utils import to_categorical\nY_array_encoded = to_categorical(Y_array)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(np.array(X_array), np.array(Y_array_encoded), test_size=0.25, random_state=SEED)\n#X_train = np.array(X_array)\n#y_train = np.array(Y_array_encoded)\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\ndatagen = ImageDataGenerator(\n    #featurewise_center=True,\n    #featurewise_std_normalization=True,\n    #rescale=1./255,\n    rotation_range=180,\n    #width_shift_range=.05,\n    #height_shift_range=.05,\n    horizontal_flip=True,\n    vertical_flip=True)\n\n# training the image preprocessing\n# compute quantities required for featurewise normalization\n# (std, mean, and principal components if ZCA whitening is applied)\ndatagen.fit(X_train, augment=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#X_train.shape, X_test.shape, y_train.shape, y_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Convolution2D\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import MaxPooling2D\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras import optimizers\n\nmodel = Sequential()\nmodel.add(Convolution2D(32, kernel_size = (3, 3), activation='relu', input_shape=(image_width, image_height, 3)))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Convolution2D(64, kernel_size=(3,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Convolution2D(96, kernel_size=(3,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Convolution2D(96, kernel_size=(3,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Convolution2D(64, kernel_size=(3,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.2))\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(128, activation='relu'))\n#model.add(Dropout(0.3))\nmodel.add(Dense(2, activation = 'softmax'))\n\n#model = Sequential()\n#model.add(Convolution2D(64, kernel_size=5, activation='sigmoid'))\n#model.add(MaxPooling2D(pool_size=2))\n#model.add(Convolution2D(32, kernel_size=3, activation='sigmoid'))\n#model.add(MaxPooling2D(pool_size=2))\n#model.add(Flatten())\n##model.add(Dropout(0.5))\n#model.add(Dense(2,activation = 'softmax'))\n#model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n\n#adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) #точность составила 0.92127\n#model.compile(optimizer=keras.optimizers.Adadelta(), loss='binary_crossentropy', metrics=['accuracy']) #точность составила 0.5\n\nmodel.summary()\n\nbatch_size = 64\nepochs = 50\n# fits the model on batches with real-time data augmentation:\nmodel.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size),steps_per_epoch = X_train.shape[0]//batch_size, epochs=epochs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train, y_train, \n          batch_size=batch_size,\n          epochs=epochs,\n          validation_data=(X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#prediction = model.predict_classes(X_test)\n#roc_auc_score(y_test[:,1], prediction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_control, y_control = [], []\nleaderboard_filenames=[]\ncategory_dir = os.path.join(TEST_DIR)\nfor image_path in os.listdir(category_dir):\n    if not (image_path.endswith('.png')):\n        continue \n    image = PIL.Image.open(os.path.join(category_dir, image_path))#.convert(\"L\")\n    if (image.width == image_width) and (image.height == image_height):\n        X_control.append(np.array(image))    \n        leaderboard_filenames.append(image_path)\nX_control_array = np.array(X_control)#.reshape(len(X_control), image_width, image_height, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"leadeboard_predictions = model.predict_proba(X_control_array)[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#leadeboard_predictions[leadeboard_predictions>0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nidx = 467\n\nplt.axis(\"off\");\nif leadeboard_predictions[idx] > 0.5:\n    plt.text(20, -5, 'HOT DOG!!!', fontdict=font)\nelse:\n    plt.text(15, -5,'not hot dog...', fontdict=font)\nplt.imshow(leaderboard_X[idx]);\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame(\n    {\n        'image_id': leaderboard_filenames, \n        'image_hot_dog_probability': leadeboard_predictions\n    }\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submit_net_daug4.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}